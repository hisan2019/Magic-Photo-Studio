
// Use correct imports as per @google/genai guidelines
import { GoogleGenAI, Type, GenerateContentResponse } from "@google/genai";
import { ChatMessage, ChatPart } from "./types";

export class GeminiService {
  /**
   * Generates a descriptive prompt based on an uploaded image and the specific menu context.
   */
  async generatePromptFromImage(imageBase64: string, menuName: string, lang: string): Promise<string> {
    const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
    
    // Explicitly structure image part to match SDK Part type
    const imagePart = {
      inlineData: {
        data: imageBase64.split(',')[1],
        mimeType: imageBase64.split(';')[0].split(':')[1]
      }
    };

    const textPart = {
      text: `Analyze this image and create a short but descriptive image generation prompt. 
             Menu Context: "${menuName}".
             Instructions: Write a 1-2 sentence prompt in ${lang === 'id' ? 'Bahasa Indonesia' : 'English'} 
             that describes the style, subject, and lighting for an AI generator.`
    };

    const response: GenerateContentResponse = await ai.models.generateContent({
      model: 'gemini-3-flash-preview',
      contents: { parts: [imagePart, textPart] },
    });

    return response.text?.trim() || "";
  }

  /**
   * Refines an existing prompt text using the reference image and menu context.
   */
  async refinePrompt(currentPrompt: string, imageBase64: string | null | undefined, menuName: string, lang: string): Promise<string> {
    const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
    
    const parts: any[] = [];
    if (imageBase64) {
      parts.push({
        inlineData: {
          data: imageBase64.split(',')[1],
          mimeType: imageBase64.split(';')[0].split(':')[1]
        }
      });
    }

    parts.push({
      text: `Enhance this prompt to be more professional and artistic: "${currentPrompt}". 
             Context: "${menuName}".
             Return ONLY the enhanced prompt string in ${lang === 'id' ? 'Bahasa Indonesia' : 'English'}.`
    });

    const response: GenerateContentResponse = await ai.models.generateContent({
      model: 'gemini-3-flash-preview',
      contents: { parts },
    });

    return response.text?.trim() || currentPrompt;
  }

  /**
   * Generates images. Uses Gemini 2.5 Flash Image
   */
  async generateImage(prompt: string, aspectRatio: string = '1:1'): Promise<string> {
    const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
    
    // Ensure the aspect ratio string matches the SDK requirements exactly
    const response: GenerateContentResponse = await ai.models.generateContent({
      model: 'gemini-2.5-flash-image',
      contents: prompt,
      config: {
        imageConfig: {
          aspectRatio: aspectRatio as any
        }
      }
    });

    const parts = response.candidates?.[0]?.content?.parts || [];
    for (const part of parts) {
      if (part.inlineData) {
        return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
      }
    }
    throw new Error("No image generated by model");
  }

  /**
   * Transforms existing images using Gemini 2.5 Flash Image
   */
  async transformImage(prompt: string, sourceImages: string[], aspectRatio: string = '1:1'): Promise<string> {
    const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
    const parts: any[] = sourceImages.map(img => ({
      inlineData: {
        data: img.split(',')[1],
        mimeType: img.split(';')[0].split(':')[1]
      }
    }));

    parts.push({ text: prompt });

    const response: GenerateContentResponse = await ai.models.generateContent({
      model: 'gemini-2.5-flash-image',
      contents: { parts },
      config: {
        imageConfig: {
          aspectRatio: aspectRatio as any
        }
      }
    });

    for (const part of response.candidates?.[0]?.content?.parts || []) {
      if (part.inlineData) {
        return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
      }
    }
    throw new Error("Transformation failed to return an image");
  }

  /**
   * Intelligent chat using multimodal gemini-3-pro-preview.
   * Handles conversion between App's ChatMessage and SDK's Content types.
   */
  async chat(history: ChatMessage[]): Promise<ChatPart[]> {
    const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
    
    // Transform chat history to SDK Content format
    const contents = history.map(msg => ({
      role: msg.role,
      parts: msg.parts.map((p: ChatPart) => {
        if (p.type === 'text') {
          return { text: p.text || "" };
        } else {
          const url = p.url || "";
          const mimeTypeMatch = url.match(/^data:(.*);base64,/);
          const dataStr = url.split(',')[1] || "";
          const mType = mimeTypeMatch ? mimeTypeMatch[1] : 'image/png';
          return {
            inlineData: {
              data: dataStr,
              mimeType: mType
            }
          };
        }
      })
    }));

    const response: GenerateContentResponse = await ai.models.generateContent({
      model: 'gemini-3-pro-preview',
      contents,
      config: { thinkingConfig: { thinkingBudget: 0 } }
    });

    const candidates = response.candidates;
    if (!candidates || candidates.length === 0) return [];

    const parts = candidates[0].content?.parts || [];
    // Convert SDK response parts back to App's ChatPart format
    return parts.map(p => {
      if (p.text) return { type: 'text' as const, text: p.text };
      if (p.inlineData) return { 
        type: 'image' as const, 
        url: `data:${p.inlineData.mimeType};base64,${p.inlineData.data}` 
      };
      return null;
    }).filter((p): p is ChatPart => p !== null);
  }

  /**
   * Structured data extraction
   */
  async extractRecipe(text: string) {
    const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
    const response: GenerateContentResponse = await ai.models.generateContent({
      model: 'gemini-3-flash-preview',
      contents: `Extract recipe details from this text: ${text}`,
      config: {
        responseMimeType: 'application/json',
        responseSchema: {
          type: Type.OBJECT,
          properties: {
            recipe_name: { type: Type.STRING },
            prep_time_minutes: { type: Type.INTEGER },
            ingredients: {
              type: Type.ARRAY,
              items: {
                type: Type.OBJECT,
                properties: {
                  name: { type: Type.STRING },
                  quantity: { type: Type.STRING }
                }
              }
            },
            instructions: { type: Type.ARRAY, items: { type: Type.STRING } }
          }
        }
      }
    });
    return JSON.parse(response.text || '{}');
  }

  /**
   * Google Search Grounding with Visualization
   */
  async getLiveVisuals(prompt: string) {
    const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
    
    const searchRes: GenerateContentResponse = await ai.models.generateContent({
      model: 'gemini-3-flash-preview',
      contents: `Search Google for current info about: "${prompt}". Summarize and then write an image prompt starting with 'IMAGE_PROMPT: '.`,
      config: { tools: [{ googleSearch: {} }] }
    });

    const text = searchRes.text || "";
    const splitIndex = text.indexOf("IMAGE_PROMPT:");
    const summary = splitIndex > -1 ? text.substring(0, splitIndex).trim() : text;
    const imgPrompt = splitIndex > -1 ? text.substring(splitIndex + 13).trim() : prompt;

    const imgUrl = await this.generateImage(imgPrompt, '16:9');

    return {
      summary,
      imageUrl: imgUrl,
      groundingMetadata: searchRes.candidates?.[0]?.groundingMetadata
    };
  }
}

export const gemini = new GeminiService();
